{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de Caracteres\n",
    "#### Entrenamiento de un modelo con tensorflow y keras para reconocer caracteres escritos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Cargar los datos de entrenamiento y prueba del conjunto de datos emnist usando tensorflow_datasets\n",
    "    ds_train, ds_test = tfds.load(\n",
    "        'emnist/balanced',  # Nombre del conjunto de datos\n",
    "        split=['train', 'test'],  # Dividir los datos en entrenamiento y prueba\n",
    "        as_supervised=True,  # Cargar los datos como pares (input, label)\n",
    "        batch_size=-1  # Cargar todos los datos en un solo lote\n",
    "    )\n",
    "    \n",
    "    # Convertir los datos de entrenamiento a formato numpy\n",
    "    (X_train, y_train) = tfds.as_numpy(ds_train)\n",
    "    \n",
    "    # Convertir los datos de prueba a formato numpy\n",
    "    (X_test, y_test) = tfds.as_numpy(ds_test)\n",
    "\n",
    "    # Rotar imágenes para corregir la orientación\n",
    "    X_train = np.rot90(X_train, k=3, axes=(1, 2))\n",
    "    X_test = np.rot90(X_test, k=3, axes=(1, 2))\n",
    "    \n",
    "    # Convertir los datos de entrenamiento a tipo float32 y normalizarlos dividiendo por 255\n",
    "    X_train = X_train.astype(\"float32\") / 255\n",
    "    \n",
    "    # Convertir los datos de prueba a tipo float32 y normalizarlos dividiendo por 255\n",
    "    X_test = X_test.astype(\"float32\") / 255\n",
    "    \n",
    "    # Devolver los datos de entrenamiento y prueba\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Cargar los datos de entrenamiento y prueba utilizando la función load_data\n",
    "    X_train, y_train, X_test, y_test = load_data()\n",
    "\n",
    "    # Crear un modelo secuencial de Keras\n",
    "    model = keras.models.Sequential([ #Inicia la red neuronal\n",
    "        # Añadir una capa de entrada que aplana las imágenes de 2D a 1D\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        # Añadir una capa densa con 256 neuronas y función de activación relu\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        # Añadir una capa de Dropout para reducir el sobreajuste\n",
    "        layers.Dropout(0.3),\n",
    "        # Añadir una capa densa con 128 neuronas y función de activación relu\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        # Añadir una capa densa con 47 neuronas (una por cada clase) y función de activación softmax\n",
    "        layers.Dense(47, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compilar el modelo con el optimizador, función de pérdida y métrica\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Entrenar el modelo con los datos de entrenamiento durante 5 épocas y validar con los datos de prueba\n",
    "    model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Devolver el modelo entrenado\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.5086 - loss: 1.7443 - val_accuracy: 0.7773 - val_loss: 0.7080\n",
      "Epoch 2/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.8651 - val_accuracy: 0.7997 - val_loss: 0.6028\n",
      "Epoch 3/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.7564 - loss: 0.7609 - val_accuracy: 0.8157 - val_loss: 0.5718\n",
      "Epoch 4/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.6966 - val_accuracy: 0.8194 - val_loss: 0.5433\n",
      "Epoch 5/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.6755 - val_accuracy: 0.8241 - val_loss: 0.5338\n",
      "Epoch 6/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.6528 - val_accuracy: 0.8317 - val_loss: 0.5113\n",
      "Epoch 7/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.6293 - val_accuracy: 0.8272 - val_loss: 0.5188\n",
      "Epoch 8/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.6195 - val_accuracy: 0.8314 - val_loss: 0.5070\n",
      "Epoch 9/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.6135 - val_accuracy: 0.8281 - val_loss: 0.5172\n",
      "Epoch 10/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.6059 - val_accuracy: 0.8335 - val_loss: 0.5041\n",
      "Epoch 11/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5874 - val_accuracy: 0.8292 - val_loss: 0.5033\n",
      "Epoch 12/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.5924 - val_accuracy: 0.8361 - val_loss: 0.4931\n",
      "Epoch 13/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8042 - loss: 0.5822 - val_accuracy: 0.8372 - val_loss: 0.4953\n",
      "Epoch 14/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8058 - loss: 0.5772 - val_accuracy: 0.8349 - val_loss: 0.4926\n",
      "Epoch 15/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.5738 - val_accuracy: 0.8368 - val_loss: 0.4945\n",
      "Epoch 16/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.5724 - val_accuracy: 0.8388 - val_loss: 0.4963\n",
      "Epoch 17/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8089 - loss: 0.5666 - val_accuracy: 0.8384 - val_loss: 0.4909\n",
      "Epoch 18/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.5628 - val_accuracy: 0.8407 - val_loss: 0.4853\n",
      "Epoch 19/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.5572 - val_accuracy: 0.8387 - val_loss: 0.4888\n",
      "Epoch 20/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.5515 - val_accuracy: 0.8379 - val_loss: 0.4851\n",
      "Epoch 21/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.5543 - val_accuracy: 0.8418 - val_loss: 0.4819\n",
      "Epoch 22/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.5506 - val_accuracy: 0.8398 - val_loss: 0.4901\n",
      "Epoch 23/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.5489 - val_accuracy: 0.8405 - val_loss: 0.4879\n",
      "Epoch 24/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.5428 - val_accuracy: 0.8377 - val_loss: 0.4886\n",
      "Epoch 25/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.5465 - val_accuracy: 0.8386 - val_loss: 0.4918\n",
      "Epoch 26/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.5410 - val_accuracy: 0.8396 - val_loss: 0.4915\n",
      "Epoch 27/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.5413 - val_accuracy: 0.8389 - val_loss: 0.4988\n",
      "Epoch 28/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.5354 - val_accuracy: 0.8435 - val_loss: 0.4790\n",
      "Epoch 29/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8156 - loss: 0.5413 - val_accuracy: 0.8391 - val_loss: 0.4879\n",
      "Epoch 30/30\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.5392 - val_accuracy: 0.8411 - val_loss: 0.4925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model = train_model()\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
